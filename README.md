
# Entangled Representation Learning in Video Frames

This code is the official implementation of the following paper:

&beta;-Multivariational Autoencoder (&beta;MVAE) for Entangled Representation Learning in Video Frames

## Exemplary result

![Time Consistency2](./examples/vid_seq2.png)
![Time Consistency3](./examples/vid_seq3.png)

The video sequences of DAVIS16 ...a. Image, b.Annotation, c.&beta;MVUnet

## Install

To create the environment, follow these commands:

```
conda create -n bmvae python=3.8
conda activate bmvae
pip install -r requirements.txt
```


## Predict

+ First, download the network weights from the [Google Drive Link.](https://drive.google.com/drive/folders/1RE_5KmpD3_SPUyp54ddLiPXCxMGDes24?usp=sharing) and put them on the **ckpts** folder. 
+ For posterior estimation,
+ For Segmentation, 
+ For Saliency detection, 





## Dependencies

+ [U-Net: Semantic segmentation with PyTorch](https://github.com/milesial/Pytorch-UNet)
+ 


## Cite



## Contact
[Fatemeh Nouri](mailto:nourifatemeh1@gmail.com)


